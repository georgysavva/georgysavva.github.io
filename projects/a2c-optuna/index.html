<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>A2C Optuna | Georgy Savva</title> <meta name="author" content="Georgy Savva"> <meta name="description" content="Advantage Actor-Critic with Optuna"> <meta name="keywords" content="Georgy Savva, georgysavva"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.jpg?2f1bbd5d9a3502fe9c388f46789a2cf4"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://georgysavva.github.io/projects/a2c-optuna/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Georgy Savva</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/cv.pdf" target="_blank">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">A2C Optuna</h1> <p class="post-description">Advantage Actor-Critic with Optuna</p> </header> <article> <p><a href="https://github.com/georgysavva/a2c-optuna" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/badge/Code-GitHub-blue?logo=github" alt="Code"></a></p> <h2 id="introduction">Introduction</h2> <p>The performance of online reinforcement algorithms such as Advantage Actor-Critic (<a href="https://arxiv.org/abs/1602.01783" rel="external nofollow noopener" target="_blank">A2C</a>) is very sensitive to hyperparameters. To automate and streamline the training of an optimal policy, this project utilizes <a href="https://optuna.org/" rel="external nofollow noopener" target="_blank">Optuna</a>, a hyperparameter search framework. We successfully find the set of parameters that solve the <a href="https://www.gymlibrary.dev/environments/mujoco/half_cheetah/" rel="external nofollow noopener" target="_blank">HalfCheetah</a> MuJoCo Gym environment.</p> <h2 id="method">Method</h2> <p>The policy’s input is the 17-dimensional continuous state of the environment. It’s trained to predict 6-dimensional action output. The training consists of training two networks: actor and critic. The actor learns to map states to actions, and the critic learns to predict the expected return from a given state. We use Generalized Advantage Estimation (<a href="https://arxiv.org/abs/1506.02438" rel="external nofollow noopener" target="_blank">GAE</a>) for advantage calculation, with normalized advantages. Optuna uses the Bayesian optimization algorithm to search for the best set of hyperparameters. We search among these: model size, discount, learning rate, generalized advantage estimate lambda, temporal difference lambda, baseline gradient steps, and batch size.</p> <h2 id="results">Results</h2> <p>We compare the performance of our best model trained by Optuna for the <code class="language-plaintext highlighter-rouge">HalfCheetah-v4</code> environment with the stable-baseline3 A2C policy, the only policy available online for the same environment. The sb3-a2c policy can be found <a href="https://huggingface.co/sb3/a2c-HalfCheetah-v3" rel="external nofollow noopener" target="_blank">here</a>.</p> <table> <thead> <tr> <th>Policy</th> <th>Average Return</th> </tr> </thead> <tbody> <tr> <td><strong>Ours</strong></td> <td>3828.84</td> </tr> <tr> <td>sb3-a2c</td> <td>3096.61</td> </tr> </tbody> </table> <p>Our model performs <code class="language-plaintext highlighter-rouge">24%</code> better than the sb3-a2c. Below are the policies’ trajectory rollouts.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/a2c_optuna/policy_rollout-480.webp 480w, /assets/img/a2c_optuna/policy_rollout-800.webp 800w, /assets/img/a2c_optuna/policy_rollout-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/a2c_optuna/policy_rollout" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="our policy rollout" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/a2c_optuna/sb3_a2c_rollout-480.webp 480w, /assets/img/a2c_optuna/sb3_a2c_rollout-800.webp 800w, /assets/img/a2c_optuna/sb3_a2c_rollout-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/a2c_optuna/sb3_a2c_rollout.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="s3b-a2c policy rollout" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> The left video is a rollout of our policy, and the right one corresponds to the sb3-a2c policy. </div> <p>From the video above, we can see that our agent achieves higher speed and runs in a more stable way compared to the sb3-a2c policy.</p> <p>Below is the set of hyperparameter values found by Optuna to train our policy.</p> <table> <thead> <tr> <th>Policy</th> <th>discount</th> <th>learning rate</th> <th>gae lambda</th> <th>td lambda</th> <th>baseline grad steps</th> <th>batch size</th> <th>normalize advantage</th> <th>reward to go</th> <th>num layers</th> <th>layer size layers</th> </tr> </thead> <tbody> <tr> <td><strong>Ours</strong></td> <td>0.99</td> <td>1.0e-3</td> <td>1.0</td> <td>1.0</td> <td>50</td> <td>25,000</td> <td>true</td> <td>true</td> <td>3</td> <td>256</td> </tr> </tbody> </table> <p>And here is the training curve for the average episode return of our policy.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/a2c_optuna/return_figure-480.webp 480w, /assets/img/a2c_optuna/return_figure-800.webp 800w, /assets/img/a2c_optuna/return_figure-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/a2c_optuna/return_figure.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="return figure" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h2 id="conclusion">Conclusion</h2> <p>This project demonstrates the efficacy of automated hyperparameter optimization using Optuna in enhancing the performance of reinforcement learning algorithms. By fine-tuning key parameters of the Advantage Actor-Critic (A2C) algorithm, we achieved a 24% improvement in average return compared to the stable-baseline3 A2C policy on the HalfCheetah MuJoCo Gym environment.</p> <p>Our approach leverages Bayesian optimization to systematically explore the hyperparameter space, resulting in a robust policy that outperforms the baseline both quantitatively and qualitatively, as evident from the higher stability and speed observed in trajectory rollouts. This highlights the potential of automated hyperparameter search frameworks like Optuna to streamline the development of efficient reinforcement learning models for complex tasks.</p> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>