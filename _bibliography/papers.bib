@string{aps = {American Physical Society,}}

@article{guzey2024hudor,
  title={HuDOR: Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards},
  author={Guzey, Irmak and Dai, Yinlong and Savva, Georgy and Bhirangi, Raunaq and Pinto, Lerrel},
  abstract={Training robots directly from human videos is
an emerging area in robotics and computer vision. While
there has been notable progress with two-fingered grippers,
learning autonomous tasks without teleoperation remains a
difficult problem for multi-fingered robot hands. A key reason
for this difficulty is that a policy trained on human hands
may not directly transfer to a robot hand with a different
morphology. In this work, we present HUDOR, a technique
that enables online fine-tuning of the policy by constructing
a reward function from the human video. Importantly, this
reward function is built using object-oriented rewards derived
from off-the-shelf point trackers, which allows for meaningful
learning signals even when the robot hand is in the visual
observation, while the human hand is used to construct the
reward. Given a single video of human solving a task, such
as gently opening a music box, HUDOR allows our four-
fingered Allegro hand to learn this task with just an hour of
online interaction. Our experiments across four tasks, show
that HUDOR outperforms alternatives with an average of 4Ã—
improvement. Code and videos are available on our website
https://object-rewards.github.io/.},
  pdf={HuDOR_ICRA_2025.pdf},
  preview={HuDOR_preview.pdf},
  selected={true},
  journal={ICRA},
  year={2025}
}